---
title: "HT7"
output: html_document
date: "2023-04-21"
---

## Paquetes de RStudio

``` {r echo=FALSE}
library(dplyr)
library(knitr)
library(rpart)       # performing regression trees
library(rsample)     # data splitting 
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(caret)       # bagging
library(e1071)
library(dummy)
library(fastDummies)
library(randomForest)
library(corrplot)
```

## 1 - Use los mismos conjuntos de entrenamiento y prueba de las hojas de trabajo pasadas para probar el algoritmo.

```{r echo=FALSE}
data <- read.csv("train.csv")
```

### Limpiando los datos

```{r echo=FALSE}
columns_used <- c()
neighborhoodNames <- c("NoRidge", "NridgHt", "StoneBr", "Timber", "Veenker", "Somerst", "ClearCr", "Crawfor", "CollgCr", "Blmngtn", "Gilbert", "NWAmes", "SawyerW", "Mitchel", "NAmes", "NPkVill", "SWISU", "Blueste", "Sawyer", "OldTown", "Edwards", "BrkSide", "BrDale", "IDOTRR", "MeadowV")

for(n in 1:length(neighborhoodNames)) {
  # Variable minuscula para nuestro uso.
  data$neighborhood[data$Neighborhood == neighborhoodNames[n]] <- n
}
columns_used <- append(columns_used, "neighborhood")

hs <- c("1Story", "2Story",	"1.5Fin",	"SLvl", "SFoyer")

for(n in 1:length(hs)) {
  # Variable minuscula para nuestro uso.
  data$houseStyle[data$HouseStyle == hs[n]] <- n
}
columns_used <- append(columns_used, "houseStyle")

 data$houseZone[data$MSZoning == "A"] <- 1
 data$houseZone[data$MSZoning == "C"] <- 2
 data$houseZone[data$MSZoning == "FV"] <- 3
 data$houseZone[data$MSZoning == "I"] <- 4
 data$houseZone[data$MSZoning == "RH"] <- 5
 data$houseZone[data$MSZoning == "RL"] <- 6
 data$houseZone[data$MSZoning == "RP"] <- 7
 data$houseZone[data$MSZoning == "RM"] <- 8
 columns_used <- append(columns_used, "houseZone")

data$houseUtilities[data$Utilities == "AllPub"] <- 1
data$houseUtilities[data$Utilities == "NoSewr"] <- 2
data$houseUtilities[data$Utilities == "NoSeWa"] <- 3
data$houseUtilities[data$Utilities == "ELO"] <- 4
columns_used <- append(columns_used, "houseUtilities")

data$roadAccess[data$Condition1 == "Artery"] <- 1
data$roadAccess[data$Condition1 == "Feedr"] <- 2
data$roadAccess[data$Condition1 == "Norm"] <- 3
data$roadAccess[data$Condition1 == "RRNn"] <- 4
data$roadAccess[data$Condition1 == "RRAn"] <- 5
data$roadAccess[data$Condition1 == "PosN"] <- 6
data$roadAccess[data$Condition1 == "PosA"] <- 7
data$roadAccess[data$Condition1 == "RRNe"] <- 8
data$roadAccess[data$Condition1 == "RRAe"] <- 9
columns_used <- append(columns_used, "roadAccess")

data$remodelated[data$YearBuilt != data$YearRemodAdd] <- 1
data$remodelated[data$YearBuilt == data$YearRemodAdd] <- 0
columns_used <- append(columns_used, "remodelated")

data$roofStyle[data$RoofStyle == "Flat"]  <- 1
data$roofStyle[data$RoofStyle == "Gable"]  <- 2
data$roofStyle[data$RoofStyle == "Gambrel"]  <- 3
data$roofStyle[data$RoofStyle == "Hip"]  <- 4
data$roofStyle[data$RoofStyle == "Mansard"]  <- 5
data$roofStyle[data$RoofStyle == "Shed"]  <- 6
columns_used <- append(columns_used, "roofStyle")

data$roofMaterial[data$RoofMatl == "ClyTile"] <- 1
data$roofMaterial[data$RoofMatl == "CompShg"] <- 2
data$roofMaterial[data$RoofMatl == "Membran"] <- 3
data$roofMaterial[data$RoofMatl == "Metal"] <- 4
data$roofMaterial[data$RoofMatl == "Roll"] <- 5
data$roofMaterial[data$RoofMatl == "Tar&Grv"] <- 6
data$roofMaterial[data$RoofMatl == "WdShake"] <- 7
data$roofMaterial[data$RoofMatl == "WdShngl"] <- 8
columns_used <- append(columns_used, "roofMaterial")

data$overallQuality <- data$OverallQual
columns_used <- append(columns_used, "overallQuality")

data$overallCondition <- data$OverallCond
columns_used <- append(columns_used, "overallCondition")


data$exteriorCondition[data$ExterCond == "Po"] <- 1
data$exteriorCondition[data$ExterCond == "Fa"] <- 2
data$exteriorCondition[data$ExterCond == "TA"] <- 3
data$exteriorCondition[data$ExterCond == "Gd"] <- 4
data$exteriorCondition[data$ExterCond == "Ex"] <- 5
columns_used <- append(columns_used, "exteriorCondition")

data$foundationMaterial[data$Foundation == "BrkTil"] <- 1
data$foundationMaterial[data$Foundation == "CBlock"] <- 2
data$foundationMaterial[data$Foundation == "PConc"] <- 3
data$foundationMaterial[data$Foundation == "Slab"] <- 4
data$foundationMaterial[data$Foundation == "Stone"] <- 5
data$foundationMaterial[data$Foundation == "Wood"] <- 6
columns_used <- append(columns_used, "foundationMaterial")

data$basement[is.na(data$BsmtQual)] <- 0
data$basement[!is.na(data$BsmtQual)] <- 1
columns_used <- append(columns_used, "basement")

data$basementCondition[data$BsmtCond == "Ex"] <- 3
data$basementCondition[data$BsmtCond == "Gd"] <- 2
data$basementCondition[data$BsmtCond != "Ex"] <- 1
data$basementCondition[data$BsmtCond != "Gd"] <- 1
data$basementCondition[is.na(data$BsmtCond)] <- 0
columns_used <- append(columns_used, "basementCondition")

data$fireplace[is.na(data$FireplaceQu)] <- 0
data$fireplace[!is.na(data$FireplaceQu)] <- 1
columns_used <- append(columns_used, "fireplace")

data$garageArea <- data$GarageArea
columns_used <- append(columns_used, "garageArea")

data$pool[is.na(data$PoolQC)] <- 0
data$pool[!is.na(data$PoolQC)] <- 1
columns_used <- append(columns_used, "pool")

data$additionalFeature[is.na(data$MiscFeature)] <- 0
data$additionalFeature[!is.na(data$MiscFeature)] <- 1
columns_used <- append(columns_used, "additionalFeature")

data$livingArea <- data$GrLivArea
columns_used <- append(columns_used, "livingArea")

data$yearBuilt <- data$YearBuilt
columns_used <- append(columns_used, "yearBuilt")


data$salePrice <- data$SalePrice
columns_used <- append(columns_used, "salePrice")

tv <- c("WD", "Oth", "New", "ConLw", "ConLI", "ConLD", "Con", "CWD", "COD")

for(n in 1:length(tv)) {
  # Variable minuscula para nuestro uso.
  data$saleType[data$SaleType == tv[n]] <- n
}
columns_used <- append(columns_used, "saleType")

msz <- c("FV", "RL", "RH", "RM" , "C (all)")

for(n in 1:length(msz)) {
  # Variable minuscula para nuestro uso.
  data$mSZoning[data$MSZoning == msz[n]] <- n
}
columns_used <- append(columns_used, "mSZoning")

clean_data <- subset(data, select = columns_used)
```


## 2 - Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte.

### Se llevara a cabo un analisis exploratorio

=> Encontrando todos los NA de la clean data

```{r}
sum(is.na(clean_data))
colSums(is.na(clean_data))
```

Se puede observar que se presentan datos vacios en "houseStyle" y en "houseZone". Por si se llevara a cabo un modelo de maquuinas vectoriales necesitaremos tener cuidado con estos datos.

=> Tendencias de la data

``` {r}
correlations <- cor(clean_data[,c("salePrice", "neighborhood", "houseStyle", "houseZone", "overallQuality", "yearBuilt")], use="pairwise.complete.obs")
corrplot(correlations, method="circle", type="lower", sig.level = 0.01, insig = "blank")
```

Se puede observar que el año donde se realizo la casa, su precio y la calidad de esta misma esta correlacionado con el vecindario, estos tres datos tienen una correlacion negativa, esto nos indica que las condiciones actuales puenden reducir a lo largo de los años.

## 3 - Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara

```{r}
clean_data$economy <- ifelse(clean_data$salePrice < 163000, "Economic", ifelse(clean_data$salePrice >= 163000 & clean_data$salePrice <= 214000, "Average", "Expensive"))
```

``` {r}
set.seed(5)
expected_result <- clean_data$salePrice
partition <- createDataPartition(y=expected_result, p=.75, list=F)
train_set <- clean_data[partition,]
test_set <- clean_data[-partition,]
```

## 4 - Genere varios (más de 2) modelos de SVM con diferentes kernels y distintos valores en los parámetros c, gamma (circular) y d (en caso de que utilice el polinomial). Puede tunear el modelo de forma automática siempre que explique los resultados.

### --> Preparar los modelos con diferentes kernels
``` {r, warning=FALSE}
train_set <- na.omit(train_set)
test_set <- na.omit(test_set)

train_set$economy <- as.factor(train_set$economy)
test_set$economy <- as.factor(test_set$economy)

modelSVM_L01<-svm(economy~., data=train_set, cost=2^10, kernel="linear")
modelSVM_L02<-svm(economy~., data=train_set, cost=2^-10, kernel="linear")
modelSVM_L03<-svm(economy~., data=train_set, cost=0.5, kernel="linear")
modelSVM_R01<-svm(economy~., data=train_set, gamma=2^-10, kernel="radial")
modelSVM_R02<-svm(economy~., data=train_set, gamma=2, kernel="radial")

# Tuneando modelos para obtener diferentes resultados
modelTunedL <- tune.svm(economy~., data=train_set, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="linear")
modelTunedP <- tune.svm(economy~., data=train_set, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="polynomial", degree = c(2,3))
```


## 5 - Use los modelos para predecir el valor de la variable respuesta
``` {r}

predictionL01<-predict(modelSVM_L01, newdata=test_set)
predictionL02<-predict(modelSVM_L02, newdata=test_set)
predictionL03<-predict(modelSVM_L03, newdata=test_set)
predictionR01<-predict(modelSVM_R01, newdata=test_set)
predictionR02<-predict(modelSVM_R02, newdata=test_set)
predictionTuned01 <- predict(modelTunedL$best.model, newdata=test_set)
predictionTuned02 <- predict(modelTunedP$best.model, newdata=test_set)
```
## 6 - Haga las matrices de confusión respectivas

Modelo modelSVM_L01
``` {r}
confusionMatrix(test_set$economy, predictionL01)
```

Modelo modelSVM_L02
``` {r}
confusionMatrix(test_set$economy, predictionL02)
```

Modelo modelSVM_L03
``` {r}
confusionMatrix(test_set$economy, predictionL03)
```


Modelo modelSVM_R01
``` {r}
confusionMatrix(test_set$economy, predictionR01)
```


Modelo modelSVM_R02
``` {r}
confusionMatrix(test_set$economy, predictionR02)
```

Modelo modelTunedL
``` {r}
confusionMatrix(test_set$economy, predictionTuned01)
```


Modelo modelTunedP
``` {r}
confusionMatrix(test_set$economy, predictionTuned02)
```

## 7 - Analice si los modelos están sobreajustados o desajustados. ¿Qué puede hacer para manejar el sobreajuste o desajuste?

Los modelos radiales parecen estar desajustados dado que su accuracy es 0.4843.
Todos los modelos adicionales tienen un accuracy de 0.9943, es posible que estén sobreajustados por lo que vamos a visualizar las gráficas de aprendizaje y de test.



## 8 - Compare los resultados obtenidos con los diferentes modelos que hizo en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores)

### Profiling de algoritmo polinomial
```{r}
train_set_prof <- train_set[,-21]
suppressWarnings({
  Rprof(memory.profiling = TRUE)
  modelTunedP <- tune.svm(economy~., data=train_set, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="polynomial", degree = c(2,3))
  Rprof(NULL)
  profile_pt_model <- NULL
  if (file.exists("Rprof.out")) {
    profile_pt_model <- summaryRprof(memory = "both")
  } else {
    cat("No se generaron datos del perfilado de memoria\n")
  }
})
```

El tiempo para el algoritmo polinomial tuneado es de `r profile_pt_model$sampling.time` segundos.
Este algoritmo se equivocó una vez según la matriz de confusión donde predijo una casa average como Economic.

Ahora con el modelo radial
```{r}
train_set_prof <- train_set[,-21]
suppressWarnings({
  Rprof(memory.profiling = TRUE)
  modelTunedR <- svm(economy~., data=train_set, gamma=2, kernel="radial")
  Rprof(NULL)
  profile_r_model <- NULL
  if (file.exists("Rprof.out")) {
    profile_r_model <- summaryRprof(memory = "both")
  } else {
    cat("No se generaron datos del perfilado de memoria\n")
  }
})
```

El tiempo de entrenamiento fue de `r profile_r_model$sampling.time` segundos. Mucho menor al modelo tuneado. Sin embargo sufre de una accuracy muy baja dado que predice todas las casas como económicas.

En conclusión, el modelo tuneado hizo un mejor trabajo generalizando el set de datos, pero en cuanto a tiempo es más pesado.

## 9 - Compare la eficiencia del mejor modelo de SVM con los resultados obtenidos en los algoritmos de las hojas de trabajo anteriores que usen la misma variable respuesta (árbol de decisión y random forest, naive bayes). ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?


### Profiling de mejor modelo de SVM - Modelo tuneado polinomial
```{r}
suppressWarnings({
  Rprof(memory.profiling = TRUE)
  modelTunedP_prof <- tune.svm(economy~., data=train_set, cost=c(0.01,0.1,0.5,1,5,10,16,20,32), kernel="polynomial", degree = c(2,3))
  Rprof(NULL)
  profile_polynomial_model <- summaryRprof(memory = "both")
})
```

### Profiling de árbol de decisión
```{r}
train_set_prof <- train_set[,-21]
suppressWarnings({
  Rprof(memory.profiling = TRUE)
  decision_tree_model <- rpart(economy~., train_set_prof, method="class")
  Rprof(NULL)
  profile_dt_model <- NULL
  if (file.exists("Rprof.out")) {
    profile_dt_model <- summaryRprof(memory = "both")
  } else {
    cat("No se generaron datos del perfilado de memoria\n")
  }
})
```

### Profiling de random forest
```{r}

suppressWarnings({
  Rprof(memory.profiling = TRUE)
  random_forest_model <- randomForest(economy~.,train_set_prof, na.action = na.omit)
  Rprof(NULL)
  profile_rf_model <- NULL
  if (file.exists("Rprof.out")) {
    profile_rf_model <- summaryRprof(memory = "both")
  } else {
    cat("No se generaron datos del perfilado de memoria\n")
  }
})

```

### Profiling de naive bayes 
```{r}
suppressWarnings({
  Rprof(memory.profiling = TRUE)
  model_naive_bayes <- naiveBayes(economy~., data=train_set)
  Rprof(NULL)
  profile_nb_model <- NULL
  if (file.exists("Rprof.out")) {
    profile_nb_model <- summaryRprof(memory = "both")
  } else {
    cat("No se generaron datos del perfilado de memoria\n")
  }
})
```

## Predicciones de modelos

### Prediccion de modelo svm tuneado polinomial
```{r}
predictionTunedP <- predict(modelTunedP_prof$best.model, newdata=test_set)
confusionMatrix(test_set$economy, predictionTunedP)
```
Como resultado del mejor modelo de SVM se obtuvo una precisión de 99.72%, ahora bien, como resultados de hojas de trabajo anteriores se obtuvieron los siguientes resultados: arbol de decisión: 80.72%, random forest: 84.9%, naive bayes: 73%. Quien tiene un valor de precisión más alto es el modelo de SVM, sin embargo, hay que tomar en cuenta que puede tener overfit y el modelo no sería generalizable, por tanto random forest puede ser una mejor opción para predecir. Ahora bien, los resultados del tiempo de procesamiento son: `r profile_polynomial_model$sampling.time` para el modelo polinomial, `r profile_dt_model$sampling.time` para el modelo de arboles de decisión, `r profile_rf_model$sampling.time` y `r profile_nb_model$sampling.time`, por tanto se sabe que el modelo que más se demoró en procesar fue: el modelo de SVM.


## 10 - Genere un buen modelo de regresión, use para esto la variable del precio de la casa directamente.

```{r}
modelSVR_01 <- svm(salePrice~. - houseUtilities, data=train_set, type="eps-regression", kernel="linear", cost=1, epsilon=0.1)
predictionReg01<-predict(modelSVR_01, newdata=test_set)

mse <- mean((test_set$salePrice - predictionReg01)^2)
rmse <- sqrt(mse)
mae <- mean(abs(test_set$salePrice - predictionReg01))
r_cuadrado_svr <- 1 - (sum((test_set$salePrice - predictionReg01)^2) / sum((test_set$salePrice - mean(test_set$salePrice))^2))


cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R cuadrado:", r_cuadrado_svr, "\n")

```


```{r}
modelTuned_SVR01 <- tune.svm(salePrice~. - houseUtilities, data=train_set, type="eps-regression", kernel="linear", cost=c(0.1,5,10,16))

mse_tuned <- mean((test_set$salePrice - predictionReg01)^2)
mse_tuned <- sqrt(mse_tuned)
mae_tuned <- mean(abs(test_set$salePrice - predictionReg01))
r_cuadrado_svr_tuned <- 1 - (sum((test_set$salePrice - predictionReg01)^2) / sum((test_set$salePrice - mean(test_set$salePrice))^2))


cat("MSE:", mse_tuned, "\n")
cat("RMSE:", mse_tuned, "\n")
cat("MAE:", mae_tuned, "\n")
cat("R cuadrado:", r_cuadrado_svr_tuned, "\n")
```
Al momento de tunear el modelo se obtiene un r cuadrado ligeramente mejor. Lo cual nos permite que el modelo se pueda ajustar mejor a los datos.


## 11 - Compare los resultados del modelo de regresión generado con los de hojas anteriores que utilicen la misma variable, como la de regresión lineal.
Considerando que el modelo de regresión es multivariable se toma como comparación el modelo de regresión lineal mutivariable de la hoja de trabajo pasada, en donde se obtuvo un r cuadrado de: 0.8231. Con svr se obtuvo un r cuadrado de 0.7485. Esto nos demuestra que el modelo de regresión multivariable de la hoja de trabajo pasada se adapta más al modelo.

